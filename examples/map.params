#!/bin/bash


: "Parameters
    - BOX_MNT_PNT  : Not used outside of this script, should be a writable area
    - REF_BASE     : The root of the reference file area
    - SAMPLE_NAME  : Sample name to be applied to the headers and filename of BAM.
    - OUTPUT_DIR   : Write results to this folder
    - INPUT_DIR    : Folder containing input data.  This most only contain data for this sample.
                      Can be:
                       - multiple BAM inputs ($INPUT_DIR/*.bam)
                       - multiple CRAM inputs ($INPUT_DIR/*.cram)
                       - mixture of BAM + CRAM inputs ($INPUT_DIR/*.*am)
                       - multiple paired FASTQ ($INPUT_DIR/*_[12].fq[.gz])
                       - multiple interleaved FASTQ ($INPUT_DIR/*.fq[.gz])
    - BWA_PARAM    : Parameters to pass directly to 'bwa mem' command line
    - CRAM         : 0=BAM 1=CRAM
    - SCRAMBLE     : Parameters to pass to scramble when 'CRAM=1'
    - CPU          : Uncomment and set to prevent all available CPUs being used.
    - TIMEZONE     : Change this if you want the web tools to use your local timezone
                      This will give you the list:
                        perl -MDateTime -e 'print join "\n", DateTime::TimeZone->all_names;'
    - PRE_EXEC[.]  : See below for details
    - POST_EXEC[.] : See below for details
 "

REF_BASE='/datastore/ref/reference_files'
BOX_MNT_PNT='/datastore'
SAMPLE_NAME='COLO-829'
INPUT_DIR=$BOX_MNT_PNT/$SAMPLE_NAME/inputs
OUTPUT_DIR=$BOX_MNT_PNT/$SAMPLE_NAME/mapping
CRAM=0
SCRAMBLE=''
BWA_PARAM='-Y'

: "Optionally force the CPU count to this value, by default all cores available are used at
   appropriate points in the flow"
#CPU=4

TIMEZONE='Europe/London'

: "PRE_EXEC - Commands to be run before the main workflow starts
    - NOTE: To allow many commands to run an array is defined, the first command must
            be assigned to 'PRE_EXEC[0]=' all following having the number in '[]' incremented by 1
            Order of addition is maintaned.
    - Can be used to stage your files, the above variables are imported before this so
      they can be used in the normal fashion

    - First block builds the reference area
      0-2  - Download reference files (mapping + WGS + WXS)
      "
# get core mapping reference files
PRE_EXEC[0]="curl -sSL --retry 10 -o $BOX_MNT_PNT/map_ref.tar.gz ftp://ftp.sanger.ac.uk/pub/cancer/cgpbox/v3+/human/map_ref_GRCh37d5.tar.gz"
PRE_EXEC[1]="tar -C $BOX_MNT_PNT -zxvf map_ref.tar.gz"
PRE_EXEC[2]="mv map_ref $REF_BASE"

: "Same as PRE_EXEC but run at the end of the workflow
    - This is an example how you could write your result to S3 by setting the environment variables and path for your bucket
    - Nice use is that you can then set any AWS image to shutdown automatically when it becomes idle"

#POST_EXEC[0]='export AWS_ACCESS_KEY_ID=XXX'
#POST_EXEC[1]='export AWS_SECRET_ACCESS_KEY=YYY'
#POST_EXEC[2]='export AWS_DEFAULT_REGION=ZZZ'
#POST_EXEC[3]='aws s3 cp result_${NAME_MT}_vs_${NAME_WT}.tar.gz s3://some-bucket/result_${NAME_MT}_vs_${NAME_WT}.tar.gz'
